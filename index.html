<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SUSTech Audio Intelligence Lab</title>
  <meta name="description" content="">
  <link rel="shortcut icon" type="image/png" href="images/icon.png">
  <link rel="stylesheet" href="css/main.css">
<link rel='stylesheet' id='open-sans-css'  href='https://fonts.googleapis.com/css?family=Open+Sans%3A300italic%2C400italic%2C600italic%2C300%2C400%2C600&#038;subset=latin%2Clatin-ext&#038;ver=4.2.4' type='text/css' media='all' />
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:600italic,600,400,400italic' rel='stylesheet' type='text/css'>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LXDPHSYPSP"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-LXDPHSYPSP');
</script>
</head>

  <body>

  <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="index.html">SUSTech Audio Intelligence Lab</a>

    <nav class="site-nav">

      <a href="#" class="menu-icon menu.open">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>  

    <div class="trigger"><h1>Navigation</h1>

 	<ul class="menu">

    <li><a href="group.html" class="page-link">Group</a>
    
    </li>

    <li><a href="publication.html" class="page-link">Publication</a>

    </li>
    
    <li><a href="teaching.html" class="page-link">Teaching</a>
    
    </li>
    
   
</ul>


     </div>  
    </nav>

  </div>

</header>

    <div class="page-content">
      <div class="wrapper">
        <style>
#circle
{
border-radius:50% 50% 50% 50%;  
}
#roundedbox {
  border: 3px solid;
  border-color:DodgerBlue;
  padding-left: 20px;
  padding-right: 20px;
  padding-top: 20px;
  padding-bottom: 10px;
  border-radius: 30px;
}
</style>

<div class="home">

<p>This is <strong>SUSTech Audio Intelligence Lab (SAIL, 南科大音频智能实验室)</strong> directed by <a href="http://zqwang7.github.io/" target="view_window">Prof. Zhong-Qiu Wang</a> in the <a href="https://cse.sustech.edu.cn/en/" target="view_window">Department of Computer Science and Engineering</a> at <a href="https://www.sustech.edu.cn/en/" target="view_window">Southern University of Science and Technology (SUSTech)</a> in <a href="https://en.wikipedia.org/wiki/Shenzhen" target="view_window">Shenzhen, China</a>.</p>
<p>We are interested in broad speech/audio signal processing and artificial intelligence problems, aiming at building machine listening systems that can robustly perceive and understand speech/audio in reverberant environments with multiple concurrent sound sources. Our current research focuses on deep learning based approaches for speech enhancement, speaker separation, speech dereverberation and robust automatic speech recognition based on a single microphone or an array of microphones, targeting at solving the cocktail party problem.</p>

</div>

<!--
<br>
<div id="roundedbox">
<p>
  <font style="font-size: 14pt" font color="red"><strong>Our group has openings for Master students (保研/考研), Ph.D. students, Post-docs, Research Associates (研究助理), and visiting students. Our group also warmly welcomes undergraduate students. If you are interested in joining us, please send the Prof. Wang your CV, or visit Prof. Wang's office in person.</strong></font>
</p>
</div>
-->

<br>
<h2>News</h2>
<div class="updates" style="height: 20em; overflow-y: scroll;">
<ul>
  <li>[06/2025] - Our paper "<i><a href="" target="view_window">Unsupervised Multi-Channel Speech Dereverberation via Diffusion</a></i>" is accepted to ICML Workshop on Machine Learning for Audio, 2025.</li>
  <li>[05/2025] - Our papers "<i><a href="https://arxiv.org/pdf/2505.22051" target="view_window">ARiSE: Auto-Regressive Multi-Channel Speech Enhancement</a></i>", "<i><a href="https://arxiv.org/pdf/2505.19493" target="view_window">Multi-Channel Acoustic Echo Cancellation Based on Direction-of-Arrival Estimation</a></i>", and "<i><a href="https://arxiv.org/pdf/2506.02773v1" target="view_window">AuralNet: Hierarchical 3D Binaural Localization of Overlapping Speakers</a></i>" are accepted to Interspeech 2025.</li>
  <li>[05/2025] - Our paper "<i><a href="https://arxiv.org/pdf/2505.05657" target="view_window">Unsupervised Blind Speech Separation with A Diffusion Prior</a></i>" is accepted to ICML 2025.</li>
  <li>[04/2025] - Our paper "<i><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5030846", target="view_window">An End-to-End Integration of Speech Separation and Recognition with Self-Supervised Learning Representation</a></i>" is accepted to Computer Speech & Language.</li>
  <li>[03/2025] - Our paper "<i><a href="http://zqwang7.github.io/publications/SuperM2M.pdf" target="view_window">SuperM2M: Supervised and Mixture-to-Mixture Co-Learning for Speech Enhancement and Noise-Robust ASR</a></i>" is accepted to Neural Networks.</li>
  <li>[12/2024] - Our paper "<i><a href="https://arxiv.org/pdf/2501.11837" target="view_window">30+ Years of Source Separation Research: Achievements and Future Challenges</a></i>" is accepted to ICASSP 2025.</li>
  <li>[08/2024] - Our paper "<i><a href="http://zqwang7.github.io/publications/TASLP2024_USDnet_Unsupervised_Speech_Dereverberation_via_Neural_Forward_Filtering.pdf" target="view_window">USDnet: Unsupervised Speech Dereverberation via Neural Forward Filtering</a></i>" is accepted to IEEE/ACM TASLP.</li>
</ul>
</div>


</div>
</div>

  <footer class="site-footer">

  <div class="wrapper">
    <div class="footer-col-wrapper">
    
        <ul class="contact-list">
          <li><strong>Contact</strong></li>
          <li>Email: <a href="mailto:wang.zhongqiu41@gmail.com">wang.zhongqiu41@gmail.com</a> or <a href="mailto:wangzq3@sustech.edu.cn">wangzq3@sustech.edu.cn</a></li>
          <li>Address: Room 517, South Tower, CoE Building, SUSTech, 1088 Xueyuan Avenue, Nanshan District, Shenzhen 518055, P.R. China</li>
        </ul>
     
    </div>
  </div>

</footer>

  </body>

</html>
